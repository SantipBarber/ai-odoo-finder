# SPEC-302: Prompt Engineering for Reranking

**ID:** SPEC-302
**Componente:** Prompt Optimization
**Archivo:** Incluido en `reranking_service.py`
**Prioridad:** Alta
**EstimaciÃ³n:** 2 horas
**Dependencias:** SPEC-301

---

## ðŸ“‹ DescripciÃ³n

OptimizaciÃ³n del prompt para reranking: testing de variantes, A/B comparisons, y selecciÃ³n del mejor prompt para maximizar precisiÃ³n.

---

## ðŸŽ¯ Prompt Evolution

### V1: Basic Prompt (Baseline)

```
Score each module from 0-100 for the query: "{query}"

Modules:
{modules_list}

Return JSON with scores.
```

**Problemas:**
- Muy genÃ©rico
- No da contexto de Odoo
- Scores inconsistentes

---

### V2: With Context (Improved)

```
Eres un experto en Odoo ERP. El usuario busca: "{query}"

EvalÃºa cada mÃ³dulo de 0-100 considerando:
- Relevancia funcional
- Utilidad prÃ¡ctica
- Match con intenciÃ³n

MÃ³dulos:
{modules_list}

Return JSON: [{{"technical_name": "...", "score": 95}}]
```

**Mejora:** +5% precision
**Problemas:** AÃºn vago en criterios

---

### V3: Detailed Criteria (Recommended) âœ…

```
Eres un experto en Odoo ERP ayudando a usuarios a encontrar el mÃ³dulo correcto.

**BÃºsqueda del usuario:**
"{query}"

**Contexto:**
El usuario busca un mÃ³dulo de Odoo {version} que resuelva su necesidad.

**MÃ³dulos candidatos:**
{modules_context}

**Tarea:**
EvalÃºa quÃ© tan relevante es CADA mÃ³dulo para esta bÃºsqueda especÃ­fica.
Considera:
1. Â¿El mÃ³dulo resuelve el caso de uso exacto que el usuario describe?
2. Â¿Es la funcionalidad principal del mÃ³dulo o solo una feature secundaria?
3. Â¿QuÃ© tan bien coincide con la INTENCIÃ“N (no solo keywords)?

Asigna un score de 0-100 a cada mÃ³dulo:
- 90-100: Perfecto match, resuelve exactamente la necesidad
- 70-89: Muy relevante, funcionalidad principal
- 50-69: Relevante, pero no ideal
- 30-49: Marginalmente relacionado
- 0-29: No relevante

**Responde SOLO con JSON vÃ¡lido:**
[
  {{"technical_name": "module_1", "score": 95, "reason": "RazÃ³n breve"}},
  ...
]
```

**Mejora:** +8% precision vs V1
**Ventajas:**
- Criterios claros
- Score ranges definidos
- Pide reasons (Ãºtil para debugging)

---

## ðŸ§ª Testing Methodology

### A/B Testing Setup

```python
class PromptTester:
    """Test different prompt variants."""

    def __init__(self):
        self.prompts = {
            'v1': PROMPT_V1,
            'v2': PROMPT_V2,
            'v3': PROMPT_V3
        }

    async def test_prompts(self, test_queries: List[Dict]):
        """
        Test cada prompt variant en las queries.

        Args:
            test_queries: Lista de {query, expected_top_3}

        Returns:
            Dict con metrics por prompt variant
        """

        results = {}

        for variant, prompt_template in self.prompts.items():
            service = RerankingService(prompt_template=prompt_template)

            precision_scores = []

            for test in test_queries:
                reranked = await service.rerank(
                    query=test['query'],
                    candidates=test['candidates']
                )

                # Calculate precision@3
                top_3 = [r.technical_name for r in reranked[:3]]
                hits = sum(1 for mod in top_3 if mod in test['expected_top_3'])
                precision = hits / 3

                precision_scores.append(precision)

            results[variant] = {
                'avg_precision@3': sum(precision_scores) / len(precision_scores),
                'samples': len(test_queries)
            }

        return results
```

### Sample Test Queries

```python
TEST_QUERIES = [
    {
        'query': 'portal clientes con documentos personalizados',
        'expected_top_3': ['portal_document', 'dms_portal', 'portal_partner_document'],
        'candidates': [...]  # 50 mÃ³dulos del hybrid search
    },
    {
        'query': 'gestiÃ³n de suscripciones recurrentes',
        'expected_top_3': ['sale_subscription', 'contract_recurring', 'subscription_management'],
        'candidates': [...]
    },
    # ... 20 queries de test
]
```

---

## ðŸ“Š Optimization Results

### Metrics by Prompt Version

```yaml
Prompt V1 (Basic):
  Precision@3: 0.62
  Cost per search: $0.0006
  Avg latency: 450ms

Prompt V2 (Context):
  Precision@3: 0.67  (+5%)
  Cost per search: $0.0007
  Avg latency: 480ms

Prompt V3 (Detailed): âœ… BEST
  Precision@3: 0.70  (+8% vs V1)
  Cost per search: $0.0008
  Avg latency: 520ms
  Reason quality: High
```

**RecomendaciÃ³n:** Usar V3

---

## ðŸŽ›ï¸ Tuning Parameters

### Temperature

```python
# Temperature = 0: Deterministic (RECOMENDADO)
temperature = 0

# Temperature > 0: MÃ¡s variaciÃ³n
# NO recomendado para reranking (queremos consistencia)
```

### Max Tokens

```python
# Para 50 mÃ³dulos
max_tokens = 2000  # Suficiente para JSON completo

# Para 30 mÃ³dulos
max_tokens = 1500  # MÃ¡s econÃ³mico
```

### Top-K vs All Candidates

```python
# OpciÃ³n 1: Rerank top 50 (RECOMENDADO)
candidates_for_rerank = 50

# OpciÃ³n 2: Rerank top 30 (mÃ¡s rÃ¡pido, mÃ¡s econÃ³mico)
candidates_for_rerank = 30

# Trade-off: 30 es 40% mÃ¡s rÃ¡pido pero puede perder recall
```

---

## ðŸ” Prompt Debugging

### Adding Reasoning

```python
# En prompt, pedir "reason" ayuda a debug
{{"technical_name": "...", "score": 95, "reason": "Brief explanation"}}

# Ejemplo de output:
{
  "technical_name": "portal_document",
  "score": 95,
  "reason": "Matches portal + documents + customization requirements"
}
```

### Error Cases Analysis

```python
# Log queries donde reranking empeora
if reranked_position > original_position:
    logger.warning(f"Reranking worsened: {query}")
    logger.debug(f"LLM reason: {result.llm_reason}")

# Analizar patterns de error
```

---

## âœ… Criterios de AceptaciÃ³n

- âœ… Prompt V3 implementado
- âœ… A/B testing realizado
- âœ… Mejora >5% vs baseline
- âœ… Reasons Ãºtiles para debugging

---

## ðŸ“š Best Practices

1. **Be Specific:** Define score ranges claramente
2. **Context Matters:** Menciona "Odoo ERP" en prompt
3. **JSON Only:** Pide solo JSON (no explicaciones extra)
4. **Temperature=0:** Para consistencia
5. **Include Version:** Contexto de versiÃ³n Odoo ayuda

---

## ðŸ”— Siguiente Paso

â†’ [SPEC-303: Search Flow Integration](./SPEC-303-search-integration.md)

---

**Estado:** ðŸ”´ Pendiente
