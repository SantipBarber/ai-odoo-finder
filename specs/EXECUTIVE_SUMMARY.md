# AI-OdooFinder - Resumen Ejecutivo de Especificaciones

**Proyecto:** AI-OdooFinder Search Improvements
**Fase Actual:** Fase 1 - DiagnÃ³stico y Benchmark
**Fecha:** 22 Noviembre 2025
**Estado:** ğŸ”´ Specs completas, pendiente de implementaciÃ³n

---

## ğŸ“Š Overview del Proyecto

### Problema Actual
El sistema de bÃºsqueda actual tiene baja precisiÃ³n (~35% Precision@3) debido a:
- Solo usa bÃºsqueda vectorial semÃ¡ntica
- 40% de mÃ³dulos sin README (embeddings pobres)
- No captura coincidencias exactas de keywords
- Sin reranking inteligente

### Objetivo
Mejorar Precision@3 de **~35%** a **>70%** mediante mejoras incrementales y medibles.

### Approach
5 fases incrementales, cada una con specs tÃ©cnicas detalladas y mÃ©tricas de Ã©xito claras.

---

## ğŸ¯ Roadmap de Fases

| Fase | DuraciÃ³n | Mejora Esperada | Estado |
|------|----------|-----------------|--------|
| **1. DiagnÃ³stico** | 1 dÃ­a | Baseline | âœ… Specs completas |
| **2. Hybrid Search** | 2-3 dÃ­as | +15-20% | ğŸ”µ Pendiente specs |
| **3. Enrichment** | 3-4 dÃ­as | +10-15% | ğŸ”µ Pendiente specs |
| **4. Reranking** | 2-3 dÃ­as | +5-10% | ğŸ”µ Pendiente specs |
| **5. Testing** | 3-4 dÃ­as | ValidaciÃ³n | ğŸ”µ Pendiente specs |

**Total:** 10-14 dÃ­as de implementaciÃ³n

---

## ğŸ“ Estructura de Specs Creadas

```
specs/
â”œâ”€â”€ README.md                          # Ãndice general del proyecto
â”œâ”€â”€ EXECUTIVE_SUMMARY.md               # Este documento
â””â”€â”€ phase-1-diagnostico/              # âœ… COMPLETO
    â”œâ”€â”€ README.md                     # Overview de Fase 1
    â”œâ”€â”€ QUICKSTART.md                 # GuÃ­a de inicio rÃ¡pido
    â”œâ”€â”€ SPEC-001-benchmark-queries.md # Dataset de 20 queries
    â”œâ”€â”€ SPEC-002-benchmark-script.md  # Script de ejecuciÃ³n
    â”œâ”€â”€ SPEC-003-metrics.md           # MÃ³dulo de mÃ©tricas IR
    â”œâ”€â”€ SPEC-004-acceptance-criteria.md # Criterios de Ã©xito
    â””â”€â”€ benchmark_queries_example.json # Template de queries
```

---

## ğŸš€ Fase 1: DiagnÃ³stico - Detalles

### Objetivo
Establecer baseline cuantitativo de calidad de bÃºsqueda y identificar patrones de fallo.

### Entregables

| # | Entregable | Archivo | Criterio de Ã‰xito |
|---|------------|---------|-------------------|
| 1 | Benchmark queries | `tests/benchmark_queries.json` | 20 queries validadas |
| 2 | MÃ³dulo de mÃ©tricas | `app/metrics/benchmark_metrics.py` | Tests passing |
| 3 | Script de benchmark | `scripts/run_benchmark.py` | Ejecuta sin errores |
| 4 | Resultados baseline | `tests/results/baseline_*.json` | P@3 < 40% |
| 5 | AnÃ¡lisis de fallos | `tests/results/failure_analysis.md` | 5+ patrones |

### MÃ©tricas de Ã‰xito

```yaml
Success Criteria:
  - âœ… 20 queries ejecutadas correctamente
  - âœ… Precision@3 baseline < 40% (confirma necesidad mejoras)
  - âœ… Diferencia clara: easy > medium > hard
  - âœ… 5+ patrones de fallo documentados
  - âœ… Todos los tests de aceptaciÃ³n PASSED
```

### Tiempo Estimado
**4-6 horas** de implementaciÃ³n concentrada

---

## ğŸ“‹ Componentes Implementables

### SPEC-001: Benchmark Queries Dataset

**QuÃ© es:**
- JSON con 20 queries representativas
- Cada query incluye resultados esperados (ground truth)
- DistribuciÃ³n: 5 easy, 10 medium, 5 hard
- Cobertura: 5+ categorÃ­as, 3+ versiones Odoo

**CÃ³mo empezar:**
```bash
cp specs/phase-1-diagnostico/benchmark_queries_example.json \
   tests/benchmark_queries.json
```

**ValidaciÃ³n crÃ­tica:**
Verificar que todos los `expected_modules` existen en la BD antes de usar.

---

### SPEC-002: Benchmark Execution Script

**QuÃ© es:**
- Script Python que ejecuta las 20 queries
- Calcula mÃ©tricas IR automÃ¡ticamente
- Genera reporte JSON con resultados

**Funciones principales:**
```python
class BenchmarkRunner:
    async def run()                    # Orquestador principal
    async def _execute_query()         # Ejecuta 1 query
    def _generate_report()             # Agrega mÃ©tricas
```

**Output:**
```json
{
  "aggregate_metrics": {
    "precision@3": 0.35,
    "precision@5": 0.42,
    "mrr": 0.412
  },
  "detailed_results": [...]
}
```

---

### SPEC-003: Metrics Calculation Module

**QuÃ© es:**
- MÃ³dulo reutilizable de mÃ©tricas IR
- Implementa Precision, Recall, MRR
- Unit testeable, bien documentado

**API:**
```python
metrics = MetricsCalculator.calculate_all(
    retrieved=["mod1", "mod2", "mod3"],
    expected=["mod1", "mod4"]
)

# metrics.precision_at_3
# metrics.recall_at_10
# metrics.mrr
```

**Tests:**
20+ unit tests con casos edge incluidos en spec.

---

### SPEC-004: Acceptance Criteria

**QuÃ© es:**
- Checklist de validaciÃ³n completo
- Tests de aceptaciÃ³n automatizados
- Template de failure analysis
- Go/No-Go decision criteria

**Key Tests:**
```python
test_benchmark_queries_count()       # 20 queries
test_baseline_metrics_present()      # MÃ©tricas calculadas
test_difficulty_gradient_exists()    # easy > medium > hard
test_failure_analysis_exists()       # AnÃ¡lisis documentado
```

---

## ğŸ¯ Quick Win Path

Si necesitas implementar rÃ¡pido (enfoque mÃ­nimo viable):

### Path de 3 horas

```bash
# 1. Setup (15 min)
mkdir -p tests/results app/metrics
cp specs/phase-1-diagnostico/benchmark_queries_example.json \
   tests/benchmark_queries.json

# 2. Implementar mÃ©tricas (45 min)
# Copiar cÃ³digo de SPEC-003 â†’ app/metrics/benchmark_metrics.py

# 3. Implementar script (1.5 horas)
# Copiar cÃ³digo de SPEC-002 â†’ scripts/run_benchmark.py
# Ajustar imports y DB session

# 4. Ejecutar y analizar (30 min)
python scripts/run_benchmark.py
# Crear failure_analysis.md bÃ¡sico
```

**Trade-off:**
- âœ… Resultados bÃ¡sicos en 3 horas
- âš ï¸ Menos validaciÃ³n y tests
- âš ï¸ Queries no validadas contra BD real

### Path Completo (recomendado: 6 horas)

Seguir [QUICKSTART.md](./phase-1-diagnostico/QUICKSTART.md) paso a paso:
- âœ… Queries validadas contra BD
- âœ… Tests unitarios completos
- âœ… Failure analysis detallado
- âœ… Confianza en resultados

---

## ğŸ“Š MÃ©tricas de InformaciÃ³n Retrieval

### Precision@k
**QuÃ© mide:** FracciÃ³n de resultados relevantes en top K

**FÃ³rmula:** `P@k = (# relevantes en top K) / K`

**InterpretaciÃ³n:**
- P@3 = 0.33 â†’ Solo 1 de cada 3 resultados es Ãºtil
- P@3 = 0.67 â†’ 2 de cada 3 resultados son Ãºtiles
- Target: >60% mÃ­nimo, >70% ideal

### Recall@k
**QuÃ© mide:** FracciÃ³n de esperados encontrados en top K

**FÃ³rmula:** `R@k = (# esperados encontrados) / (# total esperados)`

**InterpretaciÃ³n:**
- R@10 = 0.50 â†’ Encontramos solo la mitad de mÃ³dulos relevantes
- R@10 = 1.0 â†’ Encontramos todos los mÃ³dulos relevantes

### MRR (Mean Reciprocal Rank)
**QuÃ© mide:** PosiciÃ³n del primer resultado relevante

**FÃ³rmula:** `MRR = 1 / (posiciÃ³n primer relevante)`

**InterpretaciÃ³n:**
- MRR = 1.0 â†’ Primer resultado es relevante (ideal)
- MRR = 0.5 â†’ Primer relevante estÃ¡ en posiciÃ³n 2
- MRR = 0.33 â†’ Primer relevante estÃ¡ en posiciÃ³n 3

---

## ğŸ”„ Workflow de ImplementaciÃ³n

```mermaid
graph TD
    A[Leer Specs] --> B[Setup Estructura]
    B --> C[Implementar MÃ©tricas]
    C --> D[Tests Unitarios]
    D --> E{Tests Pass?}
    E -->|No| C
    E -->|SÃ­| F[Implementar Script]
    F --> G[Validar Queries]
    G --> H[Ejecutar Benchmark]
    H --> I[Analizar Resultados]
    I --> J[Failure Analysis]
    J --> K[Tests AceptaciÃ³n]
    K --> L{All Pass?}
    L -->|No| M[Revisar Issues]
    M --> H
    L -->|SÃ­| N[âœ… Fase 1 Complete]
    N --> O[Tag & Commit]
    O --> P[Proceder a Fase 2]
```

---

## ğŸš¨ Decisiones Clave a Validar

### Antes de Empezar

1. **Â¿Los expected_modules del ejemplo aplican a tu BD?**
   - NO â†’ Debes validar y ajustar todas las queries
   - SÃ â†’ Puedes usar el ejemplo directamente

2. **Â¿Tienes acceso a la API de embeddings?**
   - NO â†’ El benchmark no funcionarÃ¡
   - SÃ â†’ Asegurar que funciona correctamente

3. **Â¿Tu SearchService actual funciona?**
   - NO â†’ Arreglar primero antes de benchmark
   - SÃ â†’ Proceder con confianza

### Durante la ImplementaciÃ³n

1. **Si Precision@3 baseline > 60%**
   â†’ Sistema funciona bien, ajustar targets al alza

2. **Si Precision@3 baseline < 10%**
   â†’ Sistema roto, revisar implementaciÃ³n

3. **Si queries fallan al ejecutar**
   â†’ Validar expected_modules existen en BD

---

## âœ… Checklist de Pre-ImplementaciÃ³n

```markdown
## Antes de empezar Fase 1

### Requisitos TÃ©cnicos
- [ ] Python 3.14 instalado
- [ ] PostgreSQL 17 + pgVector accesible
- [ ] OpenRouter API key configurada
- [ ] FastAPI + SQLAlchemy funcionando

### Validaciones
- [ ] SearchService actual funciona
- [ ] Puedo ejecutar bÃºsquedas manualmente
- [ ] BD tiene mÃ³dulos indexados (>1000)
- [ ] Embeddings se generan correctamente

### Setup
- [ ] Branch creado: phase-1-diagnostico
- [ ] Specs leÃ­das completamente
- [ ] Quickstart guide revisado
- [ ] 4-6 horas bloqueadas para implementar

### Decisiones
- [ ] Â¿Usar queries de ejemplo o crear custom?
- [ ] Â¿Implementar path rÃ¡pido (3h) o completo (6h)?
- [ ] Â¿QuiÃ©n revisarÃ¡ el failure analysis?
```

---

## ğŸ“ Soporte y Referencias

### DocumentaciÃ³n
- **Specs completas:** [phase-1-diagnostico/](./phase-1-diagnostico/)
- **Quick start:** [QUICKSTART.md](./phase-1-diagnostico/QUICKSTART.md)
- **Plan maestro:** [../docs/SYSTEM_IMPROVEMENTS.md](../docs/SYSTEM_IMPROVEMENTS.md)

### Referencias TÃ©cnicas
- Precision/Recall: Manning et al., "Introduction to IR"
- MRR: TREC-8 Question Answering Track
- MÃ©tricas IR: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)

---

## ğŸ‰ PrÃ³ximos Pasos (despuÃ©s de Fase 1)

Una vez Fase 1 completa y validada:

1. **Review de resultados** con equipo
2. **DecisiÃ³n Go/No-Go** para Fase 2
3. **PriorizaciÃ³n** de mejoras segÃºn failure patterns
4. **CreaciÃ³n de specs Fase 2** (Hybrid Search)

**Contacto:** TBD para coordinar inicio de Fase 2

---

## ğŸ“ˆ Impacto Esperado del Proyecto Completo

```
Baseline (hoy):           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 35%
+ Fase 2 (Hybrid):        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 50%  (+15%)
+ Fase 3 (Enrichment):    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 65%  (+15%)
+ Fase 4 (Reranking):     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 72%  (+7%)
Target:                   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 70%+ âœ…
```

**ROI:**
- Mejora de UX: Usuarios encuentran lo que buscan 2x mÃ¡s rÃ¡pido
- ReducciÃ³n de soporte: Menos preguntas "no encuentro X"
- AdopciÃ³n: MÃ¡s confianza en el sistema de bÃºsqueda

---

**Estado actual:** âœ… Fase 1 specs completas y listas para implementar

**Siguiente acciÃ³n:** Revisar [QUICKSTART.md](./phase-1-diagnostico/QUICKSTART.md) y comenzar implementaciÃ³n

---

**Documento creado:** 22 Noviembre 2025
**VersiÃ³n:** 1.0
**Autor:** Claude (Sonnet 4.5)
